{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legal-marine",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sapphire-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "from IAdeforestation.preprocessing import *\n",
    "from IAdeforestation.tools import *\n",
    "from IAdeforestation.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caroline-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\romain.capocasa\\.conda\\envs\\keras_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\romain.capocasa\\.conda\\envs\\keras_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/remote_sensing/eurosat-resnet50/1\", tags=['train'], input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stopped-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_predict_img(img, model, raster_template, mean, std, file_path='img', crop_size=64, split_size=171, img_max_val=65535):\n",
    "    NB_CHANNEL = img.shape[0]\n",
    "    TOTAL_WIDTH = img.shape[1]\n",
    "    TOTAL_HEIGHT = img.shape[2]\n",
    "    \n",
    "    orignal_transform = raster_template.transform\n",
    "    orignal_crs = raster_template.crs\n",
    "    orignal_dtypes = raster_template.dtypes[0]\n",
    "        \n",
    "    new_img = np.array([]).reshape(0,split_size*crop_size)\n",
    "    \n",
    "    for i in range(split_size):\n",
    "        \n",
    "        batch = []\n",
    "        for j in range(split_size):\n",
    "            split_img = img[:,i*crop_size:(i+1)*crop_size,j*crop_size:(j+1)*crop_size]\n",
    "            \n",
    "            split_img = np.float32(np.moveaxis(split_img[:,:,:], 0, -1))\n",
    "            \n",
    "            split_img = normalize(split_img, mean, std)\n",
    "\n",
    "            batch.append(split_img)\n",
    "            \n",
    "        batch = np.asarray(batch)\n",
    "        y_pred = predicted_labels.append(model.predict(batch))\n",
    "        y_pred = np.ones((1,171))\n",
    "        \n",
    "        new_horizontal_band = create_horizontal_band(y_pred)\n",
    "        new_img = np.vstack([new_img, new_horizontal_band])\n",
    "        \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caroline-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_horizontal_band(y_pred, nb_image=171, img_size=64, img_maxval=65535):\n",
    "    new_band = np.array([]).reshape(img_size,0)\n",
    "    \n",
    "    for y in y_pred:\n",
    "        new_band = np.hstack([new_band, (np.ones((64,64)) * y *img_maxval)])\n",
    "    \n",
    "    return new_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "freelance-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODELS_PATH = os.path.join(\"saved_models\",\"transfer_learning\", \"Coffee\")\n",
    "MODEL_NAME = 'new1'\n",
    "\n",
    "model = load_model(os.path.join(SAVED_MODELS_PATH, 'final_cv_coffee_fall_1', 'final_cv_coffee_fall_1_2.h5'), custom_objects={'LeakyReLU':LeakyReLU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frequent-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTINEL_IMAGES_PATH = 'SentinelImages'\n",
    "\n",
    "paths = os.listdir(SENTINEL_IMAGES_PATH)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-discipline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall\\a\n"
     ]
    }
   ],
   "source": [
    "SENTINEL_IMAGES_PATH = 'SentinelImages'\n",
    "PREDICTED_PATH = 'PredictedImages'\n",
    "\n",
    "for sentinel_image_path in paths[0:1]:\n",
    "    print(sentinel_image_path)\n",
    "    raster_paths = get_raster_paths(os.path.join(SENTINEL_IMAGES_PATH, sentinel_image_path))\n",
    "    raster_dict = load_raster_img(raster_paths)\n",
    "    image_dict = resample_bands(raster_dict)\n",
    "    \n",
    "    l = list(image_dict.values())\n",
    "    orignial_img = np.asarray(l)\n",
    "    \n",
    "    final_img = np.asarray(split_predict_img(orignial_img, model, raster_dict['B02'], mean=eurosat_params['mean'], std=eurosat_params['std']))\n",
    "    \n",
    "    with rasterio.open(os.path.join(PREDICTED_PATH, sentinel_image_path + '_pred', name+'.tiff'), 'w', driver='Gtiff',\n",
    "                                                  width=final_img.shape[1],\n",
    "                                                  height=final_img.shape[2],\n",
    "                                                  count=final_img.shape[0],\n",
    "                                                    dtype=raster_dict['B02'].dtypes[0],\n",
    "                                                   crs=raster_dict['B02'].crs,\n",
    "                                                   transform=raster_dict['B02'].transform) as dst :\n",
    "            dst.write(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-african",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
